
# 개략적인 규모 추정

개략적인 규모 추정이란 보편적으로 통용되는 성능 수치상에서 사고 실험을 행하여 추정치를 계산하는 행위를 의미한다. 이는 어떤 설계가 요구사항에 부합할 것인지를 확인하기 위한 과정이다. 개략적인 규모 추정을 위해서는 2의 제곱수, 응답지연 값, 그리고 가용성에 관계된 수치들을 기본적으로 잘 이해하고 있어야 한다.

## 2의 제곱수

데이터 볼륨의 단위를 2의 제곱수로 표현하는 방법을 아는 것은 중요

- **최소 단위:** 1바이트 (8비트)
- **ASCII 메모리 크기:** 1바이트

## 모든 프로그래머가 알아야 하는 응답지연 값

다음은 프로그래머가 알아야 할 중요한 응답지연 값이다

- **L1 캐시 참조:** 매우 빠름
- **분기 예측 오류:** 약간의 지연
- **L2 캐시 참조:** 비교적 빠름
- **뮤텍스 락/언락:** 중간 정도의 지연
- **주 메모리 참조:** 느림
- **Zippy로 1KB 압축:** 빠름
- **1 Gbps 네트워크로 2KB 전송:** 중간 정도의 지연
- **메모리에서 1 MB 순차적으로 읽기:** 빠름
- **같은 데이터 센터 내에서의 메시지 왕복 지연속도:** 중간 정도의 지연
- **디스크 탐색:** 매우 느림
- **네트워크에서 1MB 순차적으로 읽기:** 느림
- **디스크에서 1MB 순차적으로 읽기:** 매우 느림
- **한 패킷의 CA로부터 네덜란드까지의 왕복 지연속도:** 매우 느림

### 결론

- 메모리는 빠르지만 디스크는 여전히 느리므로 디스크 탐색은 회피해야 한다.
- 단순한 압축 알고리즘은 빠르다.
- 가능한 데이터를 인터넷으로 전송하기 전에 압축해야 한다.
- 데이터 센터는 여러 지역에 분산되어 있으므로, 센터들 간의 데이터 전달 시간은 소요될 수 있다.

## 가용성에 관계된 수치

고가용성이란, 시스템이 오랜 시간 동안 지속적으로 중단 없이 운영될 수 있는 능력을 지칭한다. 고가용성은 퍼센트로 표현되며, 100%는 한번도 중단되지 않은 서비스를 의미한다.

SLA(Service Level Agreement)란 서비스 사업자와 고객 사이의 합의를 의미하며, 이 안에는 가용 시간이 기술되어 있다. 관습적으로 숫자 9를 표현하기 때문에 9가 많을수록 좋은 것 (99% < 99.99% < 99.9999%).

## 면접 TIP

- **근사치를 활용한 계산:** 
- **가정을 적어두기:** 계산에 앞서 가정을 명확히 기록해두는 것이 중요
- **단위를 붙이기:** 모든 계산에 단위를 명확히 표시
- **QPS, 최대 QPS, 저장소 요구량, 캐시 요구량, 서버 수 추정하기:**

- * * *

# 처리율 제한 장치의 설계 
처리율 제한 장치란 클라이언트 또도는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치를 의미한다.
제한장치를 두면 좋은 점
> DOS 공격에 의한 자원 고갈 방지
> 추가 요청에 대한 처리를 위한 서버를 줄이고 우선순위가 높은 API에 집중하므로, 비용 절감
> 서버 과부하를 막을 수 있다.

## 처리율 제한 장치의 설계 과정 
1. 문제 이해 및 설계 범위 확정
   면접관들과 소통하며 제한 장치의 요구사항을 명확히 해야한다.
   ex) 낮은 응답시간이면 곤란하고, 가능한 적은 메모리를 사용해야한다. 하지만 분산형 처리율 제한이 되어야하고 제한되었을 때 사용자에게 알려주어야하     며 제한장치의 장애가 전체 시스템에 영향을 주면 안된다.
2. 개략적인 설계안 제시 및 동의 구하기
   이때, 처리율 제한 장치를 클라이언트/ 서버 어디에 둘 것인지 정해야한다.
   클라이언트 측에 둘 경우, 쉽게 위변조가 가능하므로 추천하지 않는다.
   서버측에 둘 경우 미들웨어를 두어 API 요청을 제한할 수 있다. 이 미들웨어는 대표적으로 **API 게이트웨이** 라고 불리는 컨포넌트를 구현한다.
   이 게이트웨이는 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리등을 지원하는 완전 위탁관리형 서비스이다.
3. 처리율 제한 알고리즘 정하기
   *토큰 버킷
   *누출 버킷
   *고정 윈도 카운터
   *이동 윈도 로그
   *이동 윈도 카운터

## 처리율 제한 알고리즘

### 토큰 버킷 알고리즘
제일 많이 쓰이는 알고리즘 중 하나로 간단하고 알고리즘에 대한 세간의 이해도가 높은 편이다.

토큰 버킷은 지정된 용량을 갖는 컨테이너로, 버킷에는 사전에 설정된 양의 토큰이 주기적으로 채워진다 
이 토큰이 꽉 찬 버킷에는 더이상의 토큰은 추가되지 는다. 버킷이 가득 차게 되면 추가로 공급된 토큰은 버려진다. 각 요청 당 하나의 토큰이 사용된다.
즉 요청이 들어왔을 때, 충분한 토큰이 있는 경우 버킷에서 토큰을 꺼내 요청을 시스템에 전달한다
하지만 충분한 토큰이 없을 경우엔 해당 요청은 버려진다.

토큰 버킷 알고리즘은 버킷에 담을 수 있는 토큰의 최대 갯수인 **버킷 크기**와 초당 몇개의 토큰이 공급되는지에 관한 **토큰 공급률** 를 인자로 받는다

또 여기서 버킷의 사용갯수는 공급 제한 규칙에 따라 달라진다.( API 엔드포인트, IP 주소별 , 시스템의 처리율 제한)

### 누출 버킷 알고리즘
토큰 버킷 알고리즘과 비슷하지만, 요청 처리율이 고정되어 있다 또 FIFO 큐로 구현된다.
* 요청이 도착하면 큐가 가득 차 있는지 확인. 빈자리가 있을 경우 큐에 요청 추가
* 큐가 가득 차있는 경우 새 요청은 버린다
* 지정된 시간마다 큐에서 요청을 꺼내서 처리한다.

누출 버킷 알고리즘은 큐의 사이즈를 의미하는 **버킷 크기** 지정된 시간 당 몇개의 항목을 처리할지 지정하는 값인 **처리율** 를 인자로 받는다.

### 고정 윈도 알고리즘 
타임라인을 고정된 간격의 윈도로 나누고 각 윈도마다 카운터를 붙힌다.
* 요청이 접수되면 카운터의 값 1 증가
* 이 카운터의 값이 사전에 설정된 임계치에 돋라하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.

이 알고리즘의 가장 큰 단점은 윈도의 경계 부근에 순간적으로 많은 트래픽이 몰릴 경우 윈도에 할당된 양보다 더 많은 요청을 처리할 수 도 있다는 점이다.

### 이동 윈도 알고리즘
앞서 말한 트래픽이 몰릴 경우에 대한 고정 윈도 알고리즘의 문제를 해결한 방법이다.

* 요청의 타임스탬프를 추적한다 이 타임스탬프 값은 보통 레디스의 정렬 집합과 같은 캐시에 저장되어 있다.
* 새 요청이 오면 만료된 타임스탬프 제거
* 새 요청의 타임스탬프 로그에 추가
* 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그러지 않는 경우 처리를 거부한다.

### 이동 윈도 카운터 알고리즘
고정 윈도 알고리즘과 이동 윈도 알고리즘을 결합한 것을 의미한다. 

## 상세 설계
처리율 제한 규칙은 디스크에 보관한다. 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장한다.
클라이언트가 요청을 보내면 미들웨어로 도달한다.
처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져온다. 카운터 및 마지막 요청의 타임스탬프는 레디스 캐시에서 가져온다

### 분산 환경에서의 처리율 제한 장치의 구현 
단일서버의 경우에는 간단하지만 분산 환경의 경우 비교적 어려운데 이는 두가지의 문제인 **경쟁조건, 동기화**를 고려해야 하기 떄문이다

*경쟁조건
-두 개 처리가 스레드로 들어올 경우 두 개 요청을 처리하는 스레드가 각각 병렬로 counter를 읽지만, 둘다 다른 요청의 처리상태는 상관하지 않고 
한개만 +1만 해서 레디스에 올린다는 점이다.
이런 문제를 막기위해선 "락"을 쓰곤 하는데 락은 시스템의 성능을 상당히 떨어뜨린다는 단점이 있다. 따라서 락 말고 루아스크립트 또는 정렬 집합이라고 불리는 레디스 자료구조를 쓴다. 

*동기화
웹 계층은 무상태이므로 클라이언트가 요청을 보내면 각각 다른 제한 장치로 보내게 될 수 있다. 따라서 동기화를 진행해줘야한다.
이런 문제를 해결하기 위해선 "고정세션"을 활용하는데, 같은 클라이언트로부터의 요청을 항상 같은 처리율 제한 장치로 보내는 것을 의미한다.
하지만 이 방법은 규모확장면에서 떨어지므로 추천하지 않는다. 더 나은 해결책은 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이다.

### 마무리
*경성 처리율 제한/ 연성 처리율 제한
경성 처리율 제한: 요청의 개수는 임계치를 절대 넘을 수 없다
연성 처리율 제한: 요청 개수는 잠시동안은 임계치를 넘을 수 있다.

*이번 장에선 애플리케이션 계층에 대한 처리율 제한을 알아보았지만 다른 층에서도 처리율 제한이 가능하다.

*처리율 제한을 회피하는 법
>클라이언트 측 캐시를 사용해 API 호출 횟수를 줄인다
>처리율 제한의 임계치를 이해하고 짧은 시간동안 너무 많은 메세지를 보내지 않도록 한다
>예외나 에러를 처리하는 코드를 도입해 우아하게 복구
>재시도 로직을 구현할 땐 충분한 백오프 시간을 둔다


   

